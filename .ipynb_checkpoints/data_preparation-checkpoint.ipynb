{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Task\n",
    "1. Create a program that produces a typed parquet file (https://parquet.apache.org/) from this file:\n",
    "    https://nyc-tlc.s3.us-east-1.amazonaws.com/trip%20data/green_tripdata_2013-09.csv\n",
    "By typed we mean that the data is stored it a format that is correct for its type. For example, times are stored as timestamps, numbers as ints, doubles etc.\n",
    "If you are unable to produce a parquet file use an alternative file format that also is strongly typed.\n",
    "If you are short on time focus on typing the pick up and drop off times as well as the pick up and drop off locations.\n",
    "\n",
    "2. Create a derived dataset, from the one created above, using a SQL statement that selects all existing columns and adds these new columns:\n",
    "* One-Hot encoding for each hour of the day\n",
    "* One-Hot encoding for each day\tof the week\n",
    "* Duration in seconds of the trip\n",
    "* An int encoding to indicate if the pickup or dropoff locations were at JFK airport. (Use a bounding box from the GPS coordinates to determine this). Provide pseudo code if out of time. This column is optional.\n",
    "Save the new dataset to parquet."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Requirement\n",
    "- Install python3\n",
    "- Install apache-spark (3.0.0)\n",
    "- Install pyspark"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Task 1:\n",
    "* Using pyspark read csv\n",
    "* Rename column to underscore\n",
    "* Save dataset to 'green_trip_data.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49647"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").options(header=True, inferSchema=True, ignoreTrailingWhiteSpace=True).load('green_tripdata_2013-09.csv')\n",
    "df_clean = df.select(\n",
    "    df.VendorID.alias('vendor_id'),\n",
    "    to_timestamp(df.lpep_pickup_datetime, 'yyyy-MM-dd HH:mm:ss').alias('lpep_pickup_datetime'),\n",
    "    to_timestamp(df.Lpep_dropoff_datetime, 'yyyy-MM-dd HH:mm:ss').alias('lpep_dropoff_datetime'),\n",
    "    df.Store_and_fwd_flag.alias('store_and_fwd_flag'),\n",
    "    df.RateCodeID.alias('rate_code_id'),\n",
    "    df.Pickup_longitude.alias('pickup_longitude'),\n",
    "    df.Pickup_latitude.alias('pickup_latitude'),\n",
    "    df.Dropoff_longitude.alias('dropoff_longitude'),\n",
    "    df.Dropoff_latitude.alias('dropoff_latitude'),\n",
    "    df.Passenger_count.alias('passenger_count'),\n",
    "    df.Trip_distance.alias('trip_distance'),\n",
    "    df.Fare_amount.alias('fare_amount'),\n",
    "    df.Extra.alias('extra'),\n",
    "    df.MTA_tax.alias('mta_tax'),\n",
    "    df.Tip_amount.alias('tip_amount'),\n",
    "    df.Tolls_amount.alias('tolls_amount'),\n",
    "    df.Ehail_fee.alias('ehail_fee'),\n",
    "    df.Total_amount.alias('total_amount'),\n",
    "    df.Payment_type.alias('payment_type'),\n",
    "    df.Trip_type.alias('trip_type'),\n",
    ")\n",
    "df_clean.write.mode(\"overwrite\").parquet(\"green_trip_data.parquet\")\n",
    "df_clean.count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Task 2:\n",
    "* Parquet files can also be used to create a temporary view and then used in SQL statements.\n",
    "* SQL Statements:\n",
    "    One-Hot encoding: extract (HOUR, DAYOFWEEK), then use conditional statements\n",
    "    Duration of the trip: dropoff_datetime - pickup_datetime\n",
    "    An int encoding to indicate if the pickup or dropoff locations were at JFK airport: \n",
    "        \n",
    "        A(lat_a, lon_a), B(lat_b, lon_b), R = 6371 km\n",
    "        => AB = arccos(sin(lat_a)*sin(lat_b) + cos(lat_a)*cos(lat_b)*cos(lon_a - lon_b))*R\n",
    "        (https://en.wikipedia.org/wiki/Great-circle_distance)\n",
    "        \n",
    "        JFK airport(lat=40.6413111, lon=-73.7781391)\n",
    "        (https://en.wikipedia.org/wiki/John_F._Kennedy_International_Airport)\n",
    "        \n",
    "        JFK airport(21.04kmÂ²) -> distance is 5km\n",
    "        (https://www.airport-technology.com/features/largest-airports-america)\n",
    "* Save dataset to 'green_trip_data_prep.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49647"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_trip_data = spark.read.parquet(\"green_trip_data.parquet\")\n",
    "green_trip_data.createOrReplaceTempView(\"green_trip_data\")\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        vendor_id,\n",
    "        lpep_pickup_datetime,\n",
    "        lpep_dropoff_datetime,\n",
    "        store_and_fwd_flag,\n",
    "        rate_code_id,\n",
    "        pickup_longitude,\n",
    "        pickup_latitude,\n",
    "        dropoff_longitude,\n",
    "        dropoff_latitude,\n",
    "        passenger_count,\n",
    "        trip_distance,\n",
    "        fare_amount,\n",
    "        extra,\n",
    "        mta_tax,\n",
    "        tip_amount,\n",
    "        tolls_amount,\n",
    "        ehail_fee,\n",
    "        total_amount,\n",
    "        payment_type,\n",
    "        trip_type,\n",
    "\n",
    "        IF (HOUR(lpep_pickup_datetime) == 0, 1, 0) AS o_pickup_0,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 1, 1, 0) AS o_pickup_1,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 2, 1, 0) AS o_pickup_2,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 3, 1, 0) AS o_pickup_3,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 4, 1, 0) AS o_pickup_4,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 5, 1, 0) AS o_pickup_5,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 6, 1, 0) AS o_pickup_6,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 7, 1, 0) AS o_pickup_7,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 8, 1, 0) AS o_pickup_8,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 9, 1, 0) AS o_pickup_9,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 10, 1, 0) AS o_pickup_10,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 11, 1, 0) AS o_pickup_11,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 12, 1, 0) AS o_pickup_12,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 13, 1, 0) AS o_pickup_13,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 14, 1, 0) AS o_pickup_14,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 15, 1, 0) AS o_pickup_15,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 16, 1, 0) AS o_pickup_16,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 17, 1, 0) AS o_pickup_17,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 18, 1, 0) AS o_pickup_18,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 19, 1, 0) AS o_pickup_19,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 20, 1, 0) AS o_pickup_20,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 21, 1, 0) AS o_pickup_21,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 22, 1, 0) AS o_pickup_22,\n",
    "        IF (HOUR(lpep_pickup_datetime) == 23, 1, 0) AS o_pickup_23,\n",
    "        \n",
    "        IF (DAYOFWEEK(lpep_pickup_datetime) == 1, 1, 0) AS o_pickup_sunday,\n",
    "        IF (DAYOFWEEK(lpep_pickup_datetime) == 2, 1, 0) AS o_pickup_monday,\n",
    "        IF (DAYOFWEEK(lpep_pickup_datetime) == 3, 1, 0) AS o_pickup_tuesday,\n",
    "        IF (DAYOFWEEK(lpep_pickup_datetime) == 4, 1, 0) AS o_pickup_wednesday,\n",
    "        IF (DAYOFWEEK(lpep_pickup_datetime) == 5, 1, 0) AS o_pickup_thursday,\n",
    "        IF (DAYOFWEEK(lpep_pickup_datetime) == 6, 1, 0) AS o_pickup_friday,\n",
    "        IF (DAYOFWEEK(lpep_pickup_datetime) == 7, 1, 0) AS o_pickup_saturday,\n",
    "        \n",
    "        BIGINT(lpep_dropoff_datetime) - BIGINT(lpep_pickup_datetime) AS trip_duration,\n",
    "        \n",
    "        IF (\n",
    "            ACOS(SIN(RADIANS(40.6413111))*SIN(RADIANS(pickup_latitude)) + COS(RADIANS(40.6413111))*COS(RADIANS(pickup_latitude))*COS(RADIANS(-73.7781391) - RADIANS(pickup_longitude)))*6371 <= 5 \n",
    "            OR \n",
    "            ACOS(SIN(RADIANS(40.6413111))*SIN(RADIANS(dropoff_latitude)) + COS(RADIANS(40.6413111))*COS(RADIANS(dropoff_latitude))*COS(RADIANS(-73.7781391) - RADIANS(dropoff_longitude)))*6371 <= 5\n",
    "            , 1\n",
    "            , 0\n",
    "        ) AS at_jfk_airport\n",
    "    FROM \n",
    "        green_trip_data\n",
    "\"\"\"\n",
    "green_trip_data_prep = spark.sql(query)\n",
    "green_trip_data_prep.write.mode(\"overwrite\").parquet(\"green_trip_data_prep.parquet\")\n",
    "green_trip_data_prep.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
